// Copyright 2020 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

/* eslint-disable @typescript-eslint/no-var-requires */
/* eslint-disable node/no-extraneous-import */

import {Application, Octokit} from 'probot';
import {parseRegionTags} from './region-tag-parser';
import {logger} from 'gcf-utils';
import fetch from 'node-fetch';
import tmp from 'tmp-promise';
import * as minimatch from 'minimatch';

import tar from 'tar';
import util from 'util';
import fs from 'fs';
import {promises as pfs} from 'fs';
import path from 'path';

const streamPipeline = util.promisify(require('stream').pipeline);

type Conclusion =
  | 'success'
  | 'failure'
  | 'neutral'
  | 'cancelled'
  | 'timed_out'
  | 'action_required'
  | undefined;

interface ConfigurationOptions {
  ignoreFiles: string[];
}

const DEFAULT_CONFIGURATION: ConfigurationOptions = {
  ignoreFiles: [],
};

const CONFIGURATION_FILE_PATH = 'snippet-bot.yml';

const FULL_SCAN_ISSUE_TITLE = 'snippet-bot full scan';

class Configuration {
  private options: ConfigurationOptions;
  private minimatches: minimatch.IMinimatch[];

  constructor(options: ConfigurationOptions) {
    this.options = options;
    this.minimatches = options.ignoreFiles.map(pattern => {
      return new minimatch.Minimatch(pattern);
    });
  }

  ignoredFile(filename: string): boolean {
    return this.minimatches.some(mm => {
      return mm.match(filename);
    });
  }
}

function formatBody(
  originalBody: string,
  commentMark: string,
  addition: string
): string {
  // First cut off if we already have the commentMark.
  const markIndex = originalBody.indexOf(commentMark);
  if (markIndex >= 0) {
    originalBody = originalBody.substr(0, markIndex);
  }
  return `${originalBody}${commentMark}
${addition}
---
Report generated by [snippet-bot](https://github.com/apps/snippet-bot).
If you find problems with this result, please file an issue at:
https://github.com/googleapis/repo-automation-bots/issues.
`;
}

async function downloadFile(url: string, file: string) {
  const response = await fetch(url);
  if (response.ok) {
    return streamPipeline(response.body, fs.createWriteStream(file));
  }
  throw new Error(`unexpected response ${response.statusText}`);
}

async function getFiles(dir: string, allFiles: string[]) {
  const files = (await pfs.readdir(dir)).map(f => path.join(dir, f));
  for (const f of files) {
    if (!(await pfs.stat(f)).isDirectory()) {
      allFiles.push(f);
    }
  }
  await Promise.all(
    files.map(
      async f => (await pfs.stat(f)).isDirectory() && getFiles(f, allFiles)
    )
  );
  return allFiles;
}

export = (app: Application) => {
  const events = [
    'issues.opened',
    'issues.reopened',
    'pull_request.opened',
    'pull_request.reopened',
    'pull_request.edited',
    'pull_request.synchronized',
  ];
  app.on(events, async context => {
    const repoUrl = context.payload.repository.full_name;
    const defaultBranch = context.payload.repository.default_branch;
    let configOptions!: ConfigurationOptions | null;
    try {
      configOptions = await context.config<ConfigurationOptions>(
        CONFIGURATION_FILE_PATH
      );
    } catch (err) {
      err.message = `Error reading configuration: ${err.message}`;
      logger.error(err);
      // Now this bot is only enabled if it finds the configuration file.
      // Exiting.
      return;
    }

    if (configOptions === null) {
      logger.info(`snippet-bot is not configured for ${repoUrl}.`);
      return;
    }
    const configuration = new Configuration({
      ...DEFAULT_CONFIGURATION,
      ...configOptions,
    });
    logger.info({config: configuration});
    if (context.payload.issue?.title.includes(FULL_SCAN_ISSUE_TITLE)) {
      // full scan start
      const installationId = context.payload.installation.id;
      const commentMark = `<!-- probot comment [${installationId}]-->`;
      const issueNumber = context.payload.issue.number;
      const owner = context.payload.repository.owner.login;
      const repo = context.payload.repository.name;

      const url = `https://github.com/${owner}/${repo}/tarball/${defaultBranch}`;
      const tmpDir = tmp.dirSync();
      logger.info(`working directory: ${tmpDir.name}`);

      const file = `${tmpDir.name}/${repo}.tar.gz`;
      // Download the default branch tarball and run full scan.
      try {
        await downloadFile(url, file);
        logger.info(`Downloaded to ${file}`);
        tar.x({
          file: file,
          cwd: tmpDir.name,
          sync: true,
        });
        let archiveDir!: string;
        for (const f of await pfs.readdir(tmpDir.name)) {
          const cur = tmpDir.name + '/' + f;
          const stat = await pfs.lstat(cur);
          if (stat.isDirectory()) {
            archiveDir = cur;
          }
        }
        if (archiveDir === undefined) {
          throw new Error('Failed to extract the archive');
        }
        // Determine the short commit hash from the directory name.
        // We'll use the hash for creating permalink.
        let commitHash = defaultBranch; // Defaulting to the default branch.
        const lastDashIndex = archiveDir.lastIndexOf('-');
        if (lastDashIndex !== -1) {
          commitHash = archiveDir.substr(lastDashIndex + 1);
        }
        logger.info(`Using commit hash "${commitHash}"`);
        const files = await getFiles(archiveDir, []);

        let mismatchedTags = false;
        const failureMessages: string[] = [];

        for (const file of files) {
          if (configuration.ignoredFile(file)) {
            logger.info('ignoring file from configuration: ' + file);
            continue;
          }
          try {
            const fileContents = await pfs.readFile(file, 'utf-8');
            const parseResult = parseRegionTags(
              fileContents,
              file.replace(archiveDir + '/', '')
            );
            if (!parseResult.result) {
              mismatchedTags = true;
              for (const message of parseResult.messages) {
                // Create a link to the source code at the commit.
                const linkedMessage = message.replace(
                  /^(.+):(\d+),/,
                  `- [ ] [$1:$2](https://github.com/${owner}/${repo}/blob/${commitHash}/$1#L$2),`
                );
                failureMessages.push(linkedMessage);
              }
              parseResult.messages.join('\n');
            }
          } catch (err) {
            err.message = `Failed to read the file: ${err.message}`;
            logger.error(err);
            continue;
          }
        }
        let bodyDetail = 'Great job! No unmatching region tags found!';
        if (mismatchedTags) {
          bodyDetail = failureMessages.join('\n');
        }
        await context.github.issues.update({
          owner: owner,
          repo: repo,
          issue_number: issueNumber,
          body: formatBody(
            context.payload.issue.body,
            commentMark,
            `## snippet-bot scan result
Life is too short to manually check unmatched region tags.
Here is the result:
${bodyDetail}`
          ),
        });
      } catch (err) {
        err.message = `Failed to scan files: ${err.message}`;
        logger.error(err);
        await context.github.issues.update({
          owner: owner,
          repo: repo,
          issue_number: issueNumber,
          body: formatBody(
            context.payload.issue.body,
            commentMark,
            `## snippet-bot scan result\nFailed running the full scan: ${err}.`
          ),
        });
      } finally {
        // Clean up the directory.
        await pfs.rmdir(tmpDir.name, {recursive: true});
      }
    } // full scan end.

    if (context.payload.pull_request === undefined) {
      return;
    }
    // Check on pull requests.
    // List pull request files for the given PR
    // https://developer.github.com/v3/pulls/#list-pull-requests-files
    const listFilesParams = context.repo({
      pull_number: context.payload.pull_request.number,
      per_page: 100,
    });
    const pullRequestCommitSha = context.payload.pull_request.head.sha;
    logger.info({sha: pullRequestCommitSha});
    // TODO: handle pagination
    let filesResponse: Octokit.Response<Octokit.PullsListFilesResponse>;
    try {
      filesResponse = await context.github.pulls.listFiles(listFilesParams);
    } catch (err) {
      logger.error('---------------------');
      logger.error(err);
      return;
    }
    const files: Octokit.PullsListFilesResponseItem[] = filesResponse.data;

    let mismatchedTags = false;
    let tagsFound = false;
    const failureMessages: string[] = [];

    // If we found any new files, verify they all have matching region tags.
    for (let i = 0; files[i] !== undefined; i++) {
      const file = files[i];

      if (configuration.ignoredFile(file.filename)) {
        logger.info('ignoring file from configuration: ' + file.filename);
        continue;
      }

      if (file.status === 'removed') {
        logger.info('ignoring deleted file: ' + file.filename);
        continue;
      }

      const blob = await context.github.git.getBlob(
        context.repo({
          file_sha: file.sha,
        })
      );

      const fileContents = Buffer.from(blob.data.content, 'base64').toString(
        'utf8'
      );

      logger.info({fileContents: fileContents});
      const parseResult = parseRegionTags(fileContents, file.filename);
      if (!parseResult.result) {
        mismatchedTags = true;
        failureMessages.push(parseResult.messages.join('\n'));
      }
      if (parseResult.tagsFound) {
        tagsFound = true;
      }
    }

    const checkParams: Octokit.ChecksCreateParams = context.repo({
      name: 'Mismatched region tag',
      conclusion: 'success' as Conclusion,
      head_sha: pullRequestCommitSha,
    });

    if (mismatchedTags) {
      checkParams.conclusion = 'failure';
      checkParams.output = {
        title: 'Mismatched region tag detected.',
        summary: 'Some new files have mismatched region tag',
        text: failureMessages.join('\n'),
      };
    }

    // post the status of commit linting to the PR, using:
    // https://developer.github.com/v3/checks/
    if (tagsFound) {
      await context.github.checks.create(checkParams);
    }
  });
};
